{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "Ei8zzE07CR9V"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import fashion_mnist\n",
        "import copy\n",
        "\n",
        "# load dataset\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "ZMv-1-gtCi6p"
      },
      "outputs": [],
      "source": [
        "classes = set(y_train)\n",
        "variousSamples = list()\n",
        "for i in classes:\n",
        "  ind = np.where(y_train == i)[0][0]\n",
        "  variousSamples.append(x_train[ind])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "8nEmrnfUFPAn"
      },
      "outputs": [],
      "source": [
        "x_flatten_train = x_train.reshape(x_train.shape[0],x_train.shape[1]*x_train.shape[2],1)\n",
        "y_encoded = np.zeros((y_train.shape[0], max(classes) + 1))\n",
        "y_encoded[np.arange(y_train.shape[0]), y_train] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "ldJvYFLriFPn"
      },
      "outputs": [],
      "source": [
        "y_encoded = y_encoded.reshape(60000,10,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "BJGaU2CWmYB4"
      },
      "outputs": [],
      "source": [
        "def normalize_data(x):\n",
        "  x_norm = x.astype('float32')\n",
        "  x_norm = x_norm / 255.0\n",
        "  return x_norm\n",
        "\n",
        "x_flatten_train = normalize_data(x_flatten_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "OjkOPsC-IDZm"
      },
      "outputs": [],
      "source": [
        "layers = 3\n",
        "samples = y_train.shape[0]\n",
        "lr = 0.001\n",
        "epochs = 5\n",
        "nodesPerLayer = list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "lXxQd9FhK_ax"
      },
      "outputs": [],
      "source": [
        "nodesPerLayer.append(784)\n",
        "for i in range(0,layers):\n",
        "  nodesPerLayer.append(int(1024/(2**(i+1))))\n",
        "nodesPerLayer.append(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "pR0k8a2uXy3f"
      },
      "outputs": [],
      "source": [
        "def func(activation,a_k):\n",
        "  if(activation == \"tanh\"):\n",
        "    a_k = np.tanh(a_k)\n",
        "  else:\n",
        "    a_k = 1/(1 + np.exp(-1*a_k))\n",
        "  return a_k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "Uas-jhRzYIOm"
      },
      "outputs": [],
      "source": [
        "def derivativeFun(activation,a_k):\n",
        "  activationResult = func(activation,a_k)\n",
        "  if(activation == \"tanh\"):\n",
        "    activationResult = 1 - (activationResult**2)\n",
        "  else:\n",
        "    activationResult = activationResult - (activationResult**2)\n",
        "\n",
        "  return activationResult"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "u3_w6ojmaD52"
      },
      "outputs": [],
      "source": [
        "def decision(a_k,classificationFunction):\n",
        "  if classificationFunction == \"crossEntropy\":\n",
        "    a_k = np.exp(a_k - np.max(a_k))\n",
        "    a_k = a_k / sum(a_k)\n",
        "  return a_k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "Tn76NXflcV_N"
      },
      "outputs": [],
      "source": [
        "def OneHotEncode(C):\n",
        "  oneHot = np.zeros(C.shape)\n",
        "  oneHot[np.argmax(C)] = 1\n",
        "  return oneHot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "ErGdug_sVCXM"
      },
      "outputs": [],
      "source": [
        "def forwardProp(inputX,activation,classificationFunction,weights,bias):\n",
        "  h_k = inputX\n",
        "  PreActivations = list()\n",
        "  PostActivations = list()\n",
        "  PostActivations.append(h_k)\n",
        "  for k in range(0,layers):\n",
        "    #print(weights[k].shape,h_k.shape)\n",
        "    a_k = bias[k] + np.dot(weights[k],h_k)\n",
        "    PreActivations.append(a_k)\n",
        "    h_k = func(activation,a_k)\n",
        "    PostActivations.append(h_k)\n",
        "  a_k = bias[layers] + np.matmul(weights[layers],h_k)\n",
        "  PreActivations.append(a_k)\n",
        "  yPred = decision(a_k,classificationFunction)\n",
        "  return PreActivations,PostActivations,yPred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "d7ZFrgcUSaHK"
      },
      "outputs": [],
      "source": [
        "def backProp(real, pred, h_k, weights, activation, PreActivations):\n",
        "    a_l_L_theta = pred - real\n",
        "    currentActivationGradient = a_l_L_theta\n",
        "    WeightGradients = []\n",
        "    biasGradients = []\n",
        "    layers = len(weights) - 1\n",
        "\n",
        "    for i in range(layers, -1, -1):\n",
        "        W_i_L_theta = currentActivationGradient*np.transpose(h_k[i])\n",
        "        WeightGradients.insert(0, W_i_L_theta)\n",
        "        b_i_L_theta = np.sum(currentActivationGradient, axis=0, keepdims=True)\n",
        "        biasGradients.insert(0, b_i_L_theta)\n",
        "\n",
        "        if i > 0:\n",
        "            h_i_prev_L_theta = np.matmul(weights[i].T, currentActivationGradient)\n",
        "            currentActivationGradient = h_i_prev_L_theta * derivativeFun(activation, PreActivations[i - 1])\n",
        "\n",
        "    return WeightGradients, biasGradients\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "Ns8hWfTZyvZ6"
      },
      "outputs": [],
      "source": [
        "def stochastic_gradient_descent(nodesPerLayer,x_flatten_train,y_encoded):\n",
        "  weights = list()\n",
        "  bias = list()\n",
        "  for i in range(1,len(nodesPerLayer)):\n",
        "    w = np.random.randn(nodesPerLayer[i],nodesPerLayer[i-1])*0.1\n",
        "    b =  np.random.randn(nodesPerLayer[i],1)\n",
        "    weights.append(w)\n",
        "    bias.append(b)\n",
        "\n",
        "  for i in range(0,epochs):\n",
        "    for j in range(0,len(y_train)):\n",
        "      A,B,C = forwardProp(x_flatten_train[j],\"sigmoid\",\"crossEntropy\",weights,bias)\n",
        "      Wdelta,Bdelta = backProp(y_encoded[j],C,B,weights,\"sigmoid\",A)\n",
        "      if(j%1000 == 0):\n",
        "        print(j/1000)\n",
        "      for k in range(0,len(weights)):\n",
        "        weights[k] = weights[k] - lr*Wdelta[k]\n",
        "        bias[k] = bias[k] - lr*Bdelta[k]\n",
        "  return weights,bias"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(nodesPerLayer,x_flatten_train,y_encoded):\n",
        "  weights = list()\n",
        "  bias = list()\n",
        "  for i in range(1,len(nodesPerLayer)):\n",
        "    w = np.random.randn(nodesPerLayer[i],nodesPerLayer[i-1])*0.1\n",
        "    b =  np.random.randn(nodesPerLayer[i],1)\n",
        "    weights.append(w)\n",
        "    bias.append(b)\n",
        "  Wdelta = list()\n",
        "  Bdelta = list()\n",
        "  for i in range(0,epochs):\n",
        "    Wdelta.clear()\n",
        "    Bdelta.clear()\n",
        "    print(\"Epoch:\" + str(i))\n",
        "    for j in range(0,len(y_train)):\n",
        "      A,B,C = forwardProp(x_flatten_train[j],\"sigmoid\",\"crossEntropy\",weights,bias)\n",
        "      CurrWdelta,CurrBdelta = backProp(y_encoded[j],C,B,weights,\"sigmoid\",A)\n",
        "      if( len(Wdelta) == 0):\n",
        "        Wdelta =  copy.deepcopy(CurrWdelta)\n",
        "        Bdelta = copy.deepcopy(CurrBdelta)\n",
        "      else:\n",
        "        for k in range(0,len(Wdelta)):\n",
        "          Wdelta[k] = Wdelta[k] + CurrWdelta[k]\n",
        "          Bdelta[k] = Bdelta[k] + CurrBdelta[k]\n",
        "      if(j%1000 == 0):\n",
        "        print(j/1000)\n",
        "    for k in range(0,len(weights)):\n",
        "      weights[k] = weights[k] - lr*Wdelta[k]\n",
        "      bias[k] = bias[k] - lr*Bdelta[k]\n",
        "  return weights,bias"
      ],
      "metadata": {
        "id": "XrUyqtbh8zlJ"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainModel(optimizer,x_train,y_train,nodesPerLayer):\n",
        "  FinalWeights = list()\n",
        "  FinalBias = list()\n",
        "  if(optimizer == \"gradient_descent\"):\n",
        "    FinalWeights, FinalBias = gradient_descent(nodesPerLayer,x_train,y_train)\n",
        "  elif(optimizer == \"SGD\"):\n",
        "    FinalWeights, FinalBias = stochastic_gradient_descent(nodesPerLayer,x_train,y_train)\n",
        "  return FinalWeights,FinalBias"
      ],
      "metadata": {
        "id": "WLkW8suR9RCp"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a,b = trainModel(\"gradient_descent\",x_flatten_train,y_encoded,nodesPerLayer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdAenUJ2-OjQ",
        "outputId": "2a014dd1-e7d0-4e21-9c6a-2790d91be584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0\n",
            "0.0\n",
            "1.0\n",
            "2.0\n",
            "3.0\n",
            "4.0\n",
            "5.0\n",
            "6.0\n",
            "7.0\n",
            "8.0\n",
            "9.0\n",
            "10.0\n",
            "11.0\n",
            "12.0\n",
            "13.0\n",
            "14.0\n",
            "15.0\n",
            "16.0\n",
            "17.0\n",
            "18.0\n",
            "19.0\n",
            "20.0\n",
            "21.0\n",
            "22.0\n",
            "23.0\n",
            "24.0\n",
            "25.0\n",
            "26.0\n",
            "27.0\n",
            "28.0\n",
            "29.0\n",
            "30.0\n",
            "31.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lU8sJHCOUnqN"
      },
      "outputs": [],
      "source": [
        "def testModel(weights,bias,x_test,y_test,optimizer):\n",
        "  count = 0\n",
        "  for i in range(0,x_test.shape[0]):\n",
        "    A,B,C = forwardProp(x_test[i],\"logistic\",\"crossEntropy\",weights,bias)\n",
        "    #print(C)\n",
        "    if( y_test[i] == np.argmax(C)):\n",
        "      count+=1\n",
        "  print(\"Accuracy :\" + str((count/y_test.shape[0])*100) + \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4rmZko4FZ94n"
      },
      "outputs": [],
      "source": [
        "x_flatten_test = x_test.reshape(x_test.shape[0],x_test.shape[1]*x_test.shape[2],1)\n",
        "x_flatten_test = normalize_data(x_flatten_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V94N6E6_Z94o",
        "outputId": "f09fc0d3-e11b-41d5-fb22-bfd8d7644bef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :80.82000000000001%\n"
          ]
        }
      ],
      "source": [
        "testModel(weights,bias,x_flatten_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CRGqOH8LgmK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}